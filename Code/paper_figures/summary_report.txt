================================================================================
ROPE VS SINUSOIDAL PE: EXPERIMENTAL RESULTS SUMMARY
================================================================================
Generated: 2026-02-07 18:59:08

EXPERIMENTAL CONFIGURATION
--------------------------------------------------------------------------------
Training Grid Size: 8×8
Test Grid Sizes: 8×8, 10×10, 12×12, 15×15, 20×20
Model Architecture:
  - Layers: 8
  - Heads: 10
  - d_model: 320
  - Context length: 30
Training:
  - Epochs: 100
  - Seeds: [42, 123, 456]
  - Episodes: 5000

KEY FINDINGS
--------------------------------------------------------------------------------
1. Overall Performance:
   - Baseline (Sinusoidal PE): 28.27%
   - RoPE: 49.33%
   - Improvement: +21.07 percentage points
   - Statistical significance: p=0.1837

2. Length Generalization by Grid Size:
   8×8 (interpolation):
     Baseline: 100.00% ± 0.00%
     RoPE:     100.00% ± 0.00%
     Improvement: +0.00% ns (p=nan)
     Effect size: Cohen's d = 0.000 (negligible)
   10×10 (extrapolation):
     Baseline: 39.33% ± 40.47%
     RoPE:     83.33% ± 8.99%
     Improvement: +44.00% ns (p=0.2078)
     Effect size: Cohen's d = 1.225 (large)
   12×12 (extrapolation):
     Baseline: 2.00% ± 1.63%
     RoPE:     43.33% ± 18.57%
     Improvement: +41.33% * (p=0.0350)
     Effect size: Cohen's d = 2.560 (large)
   15×15 (extrapolation):
     Baseline: 0.00% ± 0.00%
     RoPE:     14.00% ± 13.37%
     Improvement: +14.00% ns (p=0.2127)
     Effect size: Cohen's d = 1.209 (large)
   20×20 (extrapolation):
     Baseline: 0.00% ± 0.00%
     RoPE:     6.00% ± 5.89%
     Improvement: +6.00% ns (p=0.2230)
     Effect size: Cohen's d = 1.177 (large)

3. Statistical Significance Summary:
   Highly significant (p<0.001): 0 grid sizes
   Very significant (p<0.01): 0 grid sizes
   Significant (p<0.05): 1 grid sizes
   Not significant: 4 grid sizes

CONCLUSION
--------------------------------------------------------------------------------
RoPE demonstrates STRONG advantages over sinusoidal positional encoding,
particularly in length generalization to longer sequences than seen during training.
The translation-invariant properties of RoPE enable better extrapolation
to longer context lengths without truncation.

================================================================================